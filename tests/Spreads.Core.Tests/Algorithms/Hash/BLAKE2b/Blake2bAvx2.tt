<#@ template language="C#" #>
<#@ output extension=".cs" #>
//------------------------------------------------------------------------------
//	<auto-generated>
//		This code was generated from a template.
//		Manual changes will be overwritten if the code is regenerated.
//	</auto-generated>
//------------------------------------------------------------------------------

#if HAS_INTRINSICS
using System.Runtime.Intrinsics;
using System.Runtime.Intrinsics.X86;
using System.Runtime.InteropServices;
using System.Runtime.CompilerServices;

namespace Spreads.Core.Tests.Algorithms.Hash.BLAKE2b
{
	unsafe public partial struct Blake2bContext
	{
		// SIMD algorithm described in https://eprint.iacr.org/2012/275.pdf
		[MethodImpl(MethodImplOptions.AggressiveOptimization)]
		private static void mixAvx2(ulong* sh, ulong* m)
		{
			// Rotate shuffle masks. We can safely convert the ref to a pointer because the compiler guarantees the
			// data is in a fixed location, and the ref itself is converted from a pointer. Same for the IV below.
			byte* prm = (byte*)Unsafe.AsPointer(ref MemoryMarshal.GetReference(rormask));
			var r24 = Avx2.BroadcastVector128ToVector256(prm);
			var r16 = Avx2.BroadcastVector128ToVector256(prm + Vector128<byte>.Count);

			var row1 = Avx.LoadVector256(sh);
			var row2 = Avx.LoadVector256(sh + Vector256<ulong>.Count);

			ulong* piv = (ulong*)Unsafe.AsPointer(ref MemoryMarshal.GetReference(ivle));
			var row3 = Avx.LoadVector256(piv);
			var row4 = Avx.LoadVector256(piv + Vector256<ulong>.Count);

			row4 = Avx2.Xor(row4, Avx.LoadVector256(sh + Vector256<ulong>.Count * 2)); // t[] and f[]

<#
for (int i = 0; i < 12; i++) {
	WriteLine($"\t\t\t//ROUND {i+1}");
	if (i == 0) {
#>
			var m0 = Avx2.BroadcastVector128ToVector256(m);
			var m1 = Avx2.BroadcastVector128ToVector256(m + Vector128<ulong>.Count);
			var m2 = Avx2.BroadcastVector128ToVector256(m + Vector128<ulong>.Count * 2);
			var m3 = Avx2.BroadcastVector128ToVector256(m + Vector128<ulong>.Count * 3);

<#
	}
	loadcode(i, 0);
	g1();
	loadcode(i, 1);
	g2();
	diagonalize();

	if (i == 0) {
#>
			var m4 = Avx2.BroadcastVector128ToVector256(m + Vector128<ulong>.Count * 4);
			var m5 = Avx2.BroadcastVector128ToVector256(m + Vector128<ulong>.Count * 5);
			var m6 = Avx2.BroadcastVector128ToVector256(m + Vector128<ulong>.Count * 6);
			var m7 = Avx2.BroadcastVector128ToVector256(m + Vector128<ulong>.Count * 7);

<#
	}
	loadcode(i, 2);
	g1();
	loadcode(i, 3);
	g2();
	undiagonalize();
}
#>
			row1 = Avx2.Xor(row1, row3);
			row2 = Avx2.Xor(row2, row4);
			row1 = Avx2.Xor(row1, Avx.LoadVector256(sh));
			row2 = Avx2.Xor(row2, Avx.LoadVector256(sh + Vector256<ulong>.Count));

			Avx.Store(sh, row1);
			Avx.Store(sh + Vector256<ulong>.Count, row2);
		}
	}
}
#endif
<#+

void diagonalize() {
#>
			//DIAGONALIZE
			row4 = Avx2.Permute4x64(row4, 0b_10_01_00_11);
			row3 = Avx2.Permute4x64(row3, 0b_01_00_11_10);
			row2 = Avx2.Permute4x64(row2, 0b_00_11_10_01);

<#+
}

void undiagonalize() {
#>
			//UNDIAGONALIZE
			row4 = Avx2.Permute4x64(row4, 0b_00_11_10_01);
			row3 = Avx2.Permute4x64(row3, 0b_01_00_11_10);
			row2 = Avx2.Permute4x64(row2, 0b_10_01_00_11);

<#+
}

void g1() {
#>

			//G1
			row1 = Avx2.Add(Avx2.Add(row1, b0), row2);
			row4 = Avx2.Xor(row4, row1);
			row4 = Avx2.Shuffle(row4.AsUInt32(), 0b_10_11_00_01).AsUInt64();

			row3 = Avx2.Add(row3, row4);
			row2 = Avx2.Xor(row2, row3);
			row2 = Avx2.Shuffle(row2.AsByte(), r24).AsUInt64();

<#+
}

void g2() {
#>

			//G2
			row1 = Avx2.Add(Avx2.Add(row1, b0), row2);
			row4 = Avx2.Xor(row4, row1);
			row4 = Avx2.Shuffle(row4.AsByte(), r16).AsUInt64();

			row3 = Avx2.Add(row3, row4);
			row2 = Avx2.Xor(row2, row3);
			row2 = Avx2.Xor(Avx2.ShiftRightLogical(row2, 63), Avx2.Add(row2, row2));

<#+
}

void loadcode(int round, int part) {
	int r = round % 10 * 10 + part;
	switch (r) {
		case 0:
#>
			<#= round == 0 ? "var " : "" #>t0 = Avx2.UnpackLow(m0, m1);
			<#= round == 0 ? "var " : "" #>t1 = Avx2.UnpackLow(m2, m3);
<#+
			break;
		case 1:
#>
			t0 = Avx2.UnpackHigh(m0, m1);
			t1 = Avx2.UnpackHigh(m2, m3);
<#+
			break;
		case 2:
#>
			t0 = Avx2.UnpackLow(m4, m5);
			t1 = Avx2.UnpackLow(m6, m7);
<#+
			break;
		case 3:
#>
			t0 = Avx2.UnpackHigh(m4, m5);
			t1 = Avx2.UnpackHigh(m6, m7);
<#+
			break;
		case 10:
#>
			t0 = Avx2.UnpackLow(m7, m2);
			t1 = Avx2.UnpackHigh(m4, m6);
<#+
			break;
		case 11:
#>
			t0 = Avx2.UnpackLow(m5, m4);
			t1 = Avx2.AlignRight(m3, m7, 8);
<#+
			break;
		case 12:
#>
			t0 = Avx2.Shuffle(m0.AsUInt32(), 0b_01_00_11_10).AsUInt64();
			t1 = Avx2.UnpackHigh(m5, m2);
<#+
			break;
		case 13:
#>
			t0 = Avx2.UnpackLow(m6, m1);
			t1 = Avx2.UnpackHigh(m3, m1);
<#+
			break;
		case 20:
#>
			t0 = Avx2.AlignRight(m6, m5, 8);
			t1 = Avx2.UnpackHigh(m2, m7);
<#+
			break;
		case 21:
#>
			t0 = Avx2.UnpackLow(m4, m0);
			t1 = Avx2.Blend(m1.AsUInt32(), m6.AsUInt32(), 0b_1100_1100).AsUInt64();
<#+
			break;
		case 22:
#>
			t0 = Avx2.Blend(m5.AsUInt32(), m1.AsUInt32(), 0b_1100_1100).AsUInt64();
			t1 = Avx2.UnpackHigh(m3, m4);
<#+
			break;
		case 23:
#>
			t0 = Avx2.UnpackLow(m7, m3);
			t1 = Avx2.AlignRight(m2, m0, 8);
<#+
			break;
		case 30:
#>
			t0 = Avx2.UnpackHigh(m3, m1);
			t1 = Avx2.UnpackHigh(m6, m5);
<#+
			break;
		case 31:
#>
			t0 = Avx2.UnpackHigh(m4, m0);
			t1 = Avx2.UnpackLow(m6, m7);
<#+
			break;
		case 32:
#>
			t0 = Avx2.Blend(m1.AsUInt32(), m2.AsUInt32(), 0b_1100_1100).AsUInt64();
			t1 = Avx2.Blend(m2.AsUInt32(), m7.AsUInt32(), 0b_1100_1100).AsUInt64();
<#+
			break;
		case 33:
#>
			t0 = Avx2.UnpackLow(m3, m5);
			t1 = Avx2.UnpackLow(m0, m4);
<#+
			break;
		case 40:
#>
			t0 = Avx2.UnpackHigh(m4, m2);
			t1 = Avx2.UnpackLow(m1, m5);
<#+
			break;
		case 41:
#>
			t0 = Avx2.Blend(m0.AsUInt32(), m3.AsUInt32(), 0b_1100_1100).AsUInt64();
			t1 = Avx2.Blend(m2.AsUInt32(), m7.AsUInt32(), 0b_1100_1100).AsUInt64();
<#+
			break;
		case 42:
#>
			t0 = Avx2.Blend(m7.AsUInt32(), m5.AsUInt32(), 0b_1100_1100).AsUInt64();
			t1 = Avx2.Blend(m3.AsUInt32(), m1.AsUInt32(), 0b_1100_1100).AsUInt64();
<#+
			break;
		case 43:
#>
			t0 = Avx2.AlignRight(m6, m0, 8);
			t1 = Avx2.Blend(m4.AsUInt32(), m6.AsUInt32(), 0b_1100_1100).AsUInt64();
<#+
			break;
		case 50:
#>
			t0 = Avx2.UnpackLow(m1, m3);
			t1 = Avx2.UnpackLow(m0, m4);
<#+
			break;
		case 51:
#>
			t0 = Avx2.UnpackLow(m6, m5);
			t1 = Avx2.UnpackHigh(m5, m1);
<#+
			break;
		case 52:
#>
			t0 = Avx2.Blend(m2.AsUInt32(), m3.AsUInt32(), 0b_1100_1100).AsUInt64();
			t1 = Avx2.UnpackHigh(m7, m0);
<#+
			break;
		case 53:
#>
			t0 = Avx2.UnpackHigh(m6, m2);
			t1 = Avx2.Blend(m7.AsUInt32(), m4.AsUInt32(), 0b_1100_1100).AsUInt64();
<#+
			break;
		case 60:
#>
			t0 = Avx2.Blend(m6.AsUInt32(), m0.AsUInt32(), 0b_1100_1100).AsUInt64();
			t1 = Avx2.UnpackLow(m7, m2);
<#+
			break;
		case 61:
#>
			t0 = Avx2.UnpackHigh(m2, m7);
			t1 = Avx2.AlignRight(m5, m6, 8);
<#+
			break;
		case 62:
#>
			t0 = Avx2.UnpackLow(m0, m3);
			t1 = Avx2.Shuffle(m4.AsUInt32(), 0b_01_00_11_10).AsUInt64();
<#+
			break;
		case 63:
#>
			t0 = Avx2.UnpackHigh(m3, m1);
			t1 = Avx2.Blend(m1.AsUInt32(), m5.AsUInt32(), 0b_1100_1100).AsUInt64();
<#+
			break;
		case 70:
#>
			t0 = Avx2.UnpackHigh(m6, m3);
			t1 = Avx2.Blend(m6.AsUInt32(), m1.AsUInt32(), 0b_1100_1100).AsUInt64();
<#+
			break;
		case 71:
#>
			t0 = Avx2.AlignRight(m7, m5, 8);
			t1 = Avx2.UnpackHigh(m0, m4);
<#+
			break;
		case 72:
#>
			t0 = Avx2.UnpackHigh(m2, m7);
			t1 = Avx2.UnpackLow(m4, m1);
<#+
			break;
		case 73:
#>
			t0 = Avx2.UnpackLow(m0, m2);
			t1 = Avx2.UnpackLow(m3, m5);
<#+
			break;
		case 80:
#>
			t0 = Avx2.UnpackLow(m3, m7);
			t1 = Avx2.AlignRight(m0, m5, 8);
<#+
			break;
		case 81:
#>
			t0 = Avx2.UnpackHigh(m7, m4);
			t1 = Avx2.AlignRight(m4, m1, 8);
<#+
			break;
		case 82:
#>
			t0 = m6;
			t1 = Avx2.AlignRight(m5, m0, 8);
<#+
			break;
		case 83:
#>
			t0 = Avx2.Blend(m1.AsUInt32(), m3.AsUInt32(), 0b_1100_1100).AsUInt64();
			t1 = m2;
<#+
			break;
		case 90:
#>
			t0 = Avx2.UnpackLow(m5, m4);
			t1 = Avx2.UnpackHigh(m3, m0);
<#+
			break;
		case 91:
#>
			t0 = Avx2.UnpackLow(m1, m2);
			t1 = Avx2.Blend(m3.AsUInt32(), m2.AsUInt32(), 0b_1100_1100).AsUInt64();
<#+
			break;
		case 92:
#>
			t0 = Avx2.UnpackHigh(m7, m4);
			t1 = Avx2.UnpackHigh(m1, m6);
<#+
			break;
		case 93:
#>
			t0 = Avx2.AlignRight(m7, m5, 8);
			t1 = Avx2.UnpackLow(m6, m0);
<#+
			break;
	}
#>
			<#= round == 0 && part == 0 ? "var " : "" #>b0 = Avx2.Blend(t0.AsUInt32(), t1.AsUInt32(), 0b_1111_0000).AsUInt64();
<#+
}
#>
